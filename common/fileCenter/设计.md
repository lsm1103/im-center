## todo dicom文件支持分片上传到对象存储
- 构建分片上传文件夹时，要么前端传入的md5值为真实md5，要么传入studyinstanceuid（唯一标示）来做md5值，要么后端生成雪花id来做md5值，然后构建fid
- 构建分片上传文件夹时，先生成一个雪花id构建fid作为临时id，返回给前端，等上传完成在叠加所有dcm文件计算md5值，然后更新fid，通知前端
  问题是要保留studyinstanceuid，还是要通过md5来做标识；
  studyinstanceuid前端可能读取不到，那需要后端读取上传的第一个dcm分片，这样逻辑好复杂；

- todo 分片id规则：数字.dcm

## todo dicom文件上传到对象存储后，什么时候触发自动运行dicom转换？
- 手动触发
- 自动触发；维护一个脚本自动触发条件配置，每次上传完成后，自动触发脚本，脚本自动触发转换；然后把脚本跑后的产物回写到该dicom文件元数据里面
> 已经完成

todo 预测结束后的结果产物怎么处理？
- 手动触发
- 自动触发；维护一个脚本自动触发条件配置，把seg进行dicom转换后增加到原dicom转化的json文件里；把其他不需要脚本处理的文件存储到对象存储的normalfile里面，并把fid更新到dicom文件元数据里面；可以并发进行
> 已经完成

## todo 分布式存储需要实现定时健康监控
## todo 分布式存储需要实现安全动态扩容
- 分布式存储的配置，新增配置接口，需要对新增进行检查
  todo 分布式存储需要实现高可用
- 主备节点，主节点挂掉，自动切换到备节点；备用节点需要做到于主节点数据一致（可以上传的时候并发到备节点存储多份；也可以定时同步）
  todo 分布式存储需要实现高并发
- 中心化多节点设计；可以一主多备（主写备读，通过负载均衡把请求打到各个备用节点上，量大可以把读请求放到队列进行排队，可以把相同请求只打到节点一次由网关把结果给多个相同的请求）
- 去中心化多节点设计：用raft共识算法，组成raft集群
  todo 分布式存储可以实现alist项目功能，把其他产品的网盘、oss等产品集成进来，实现不花钱的大网盘功能（垃圾佬功能，发布版本不加，可以做另外版本）。


## 流程
- 登入 -> 获取token
- 上传dicom文件
  分片：
  构建分片上传相关初始化文件 ->
  拿返回的fid进行并发分片上传（分片id为数字序号，所以需要对dcm文件名改为数字序号）->
  如果有上传失败的分片或者暂停了，可以把未上传的分片进行重传 ->
  请求分片合并接口来结束分片上传，传回的fid才是持久化的fid ->
  可以
